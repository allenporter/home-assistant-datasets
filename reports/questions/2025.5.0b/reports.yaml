---
- model_id: claude-3-5-sonnet
  good_percent: 67.8%
  confidence_interval: 11.9%
  good: 40
  total: 59
  duration_ms:
    total: 262205.56
    avg: 4444.16
    min: 2541.89
    max: 10721.86
- model_id: gemini-1.5-flash
  good_percent: 63.6%
  confidence_interval: 12.7%
  good: 35
  total: 55
  token_avg:
    input_tokens: 2347.56
    cached_input_tokens: 0.0
    output_tokens: 12.84
    n_count: 110
  token_sum:
    input_tokens: 129116
    cached_input_tokens: 0
    output_tokens: 706
    n_count: 110
  token_input_cache_ratio: 0.0
  duration_ms:
    total: 48183.28
    avg: 876.06
    min: 761.6
    max: 1057.36
- model_id: gemini-2.0-flash
  good_percent: 63.6%
  confidence_interval: 12.7%
  good: 35
  total: 55
  token_avg:
    input_tokens: 2840.91
    cached_input_tokens: 0.0
    output_tokens: 12.84
    n_count: 110
  token_sum:
    input_tokens: 156250
    cached_input_tokens: 0
    output_tokens: 706
    n_count: 110
  token_input_cache_ratio: 0.0
  duration_ms:
    total: 54729.54
    avg: 995.08
    min: 841.24
    max: 1213.85
- model_id: gemini-2.0-flash-lite
  good_percent: 43.6%
  confidence_interval: 13.1%
  good: 24
  total: 55
  token_avg:
    input_tokens: 1817.8
    cached_input_tokens: 0.0
    output_tokens: 23.67
    n_count: 76
  token_sum:
    input_tokens: 99979
    cached_input_tokens: 0
    output_tokens: 1302
    n_count: 76
  token_input_cache_ratio: 0.0
  duration_ms:
    total: 37456.58
    avg: 681.03
    min: 427.36
    max: 993.82
- model_id: gpt-3.5
  good_percent: 63.6%
  confidence_interval: 12.7%
  good: 35
  total: 55
  token_avg:
    input_tokens: 3663.91
    cached_input_tokens: 0.0
    output_tokens: 28.42
    n_count: 110
  token_sum:
    input_tokens: 201515
    cached_input_tokens: 0
    output_tokens: 1563
    n_count: 110
  token_input_cache_ratio: 0.0
  duration_ms:
    total: 116761.38
    avg: 2122.93
    min: 1403.56
    max: 6594.2
- model_id: gpt-4o-mini
  good_percent: 54.5%
  confidence_interval: 13.2%
  good: 30
  total: 55
  token_avg:
    input_tokens: 3644.91
    cached_input_tokens: 0.0
    output_tokens: 23.85
    n_count: 110
  token_sum:
    input_tokens: 200470
    cached_input_tokens: 0
    output_tokens: 1312
    n_count: 110
  token_input_cache_ratio: 0.0
  duration_ms:
    total: 153273.13
    avg: 2786.78
    min: 1575.75
    max: 8280.77
- model_id: llama3.1
  good_percent: 50.9%
  confidence_interval: 13.2%
  good: 28
  total: 55
  duration_ms:
    total: 255945.29
    avg: 4653.55
    min: 3904.11
    max: 8143.83

